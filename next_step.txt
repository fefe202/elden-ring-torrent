- cercare i file attraverso attributi (attore, regista, genere)
- script che crea un test molto più corposo
- script che crea grafici dalle metriche raccolte

A. Self-Healing e Replica (Il "Tallone d'Achille")
Nel tuo NaivePeer, quando carichi un file, lo replichi su 3 nodi (Successors) ``. Ottimo. Ma cosa succede quando un nodo muore (Crash, non Graceful Leave)?

Il failure_detector in base.py se ne accorge e lo rimuove dalla lista known_peers.

L'anello di hashing cambia.

PROBLEMA: Il sistema non ripristina automaticamente il fattore di replica. Se avevi 3 copie e un nodo muore, ne rimangono 2. Se ne muore un altro, 1. Se muore il terzo, perdi il dato.

Soluzione "Pro": Implementare un thread di Active Anti-Entropy o Repair. Periodicamente, un nodo controlla i file di cui è Primary e verifica se i Successors hanno i dati. Se non li hanno (o se un successor è cambiato), invia i dati.

Soluzione "Light" (Consigliata): Nel report, evidenzia chiaramente che il sistema gestisce il failover (le letture continuano perché ci sono altre repliche), ma che il self-healing automatico è un "future work". Se hai tempo, implementa un semplice controllo periodico: "Sono responsabile di questo Hash? Ho 3 repliche? No? Replicane una al nuovo vicino."

B. Concorrenza e Race Conditions
Stai usando threading.Lock() per proteggere le strutture dati locali (known_peers), il che va bene ``. Ma sui file?

Cosa succede se due client caricano contemporaneamente un file con lo stesso nome ma contenuto diverso? L'ultimo vince (LWW - Last Write Wins)? O si crea un conflitto?

Attualmente il tuo sistema sovrascrive brutalmente.

Correzione: Non serve implementare Vector Clocks (troppo complesso ora), ma potresti aggiungere un semplice Timestamp ai metadati. Quando leggi, se trovi versioni diverse su repliche diverse (durante una Search), restituisci quella con il timestamp più alto. Questo si chiama Read Repair.

C. Gestione dei Risultati Parziali (Metadata Peer)
Nel MetadataPeer, fai uno "Scatter-Gather" interrogando 3 shard in parallelo ``.

Nel codice vedo: futures.append(executor.submit(self._fetch_remote_index, ...))

Poi: for f in concurrent.futures.as_completed(futures): ...

Domanda: Cosa succede se uno shard è lento o in timeout? Attualmente sembra che il thread aspetti o fallisca silenziosamente.

Miglioramento: Assicurati che se uno shard fallisce (timeout), la ricerca ritorni comunque i risultati parziali con un flag partial_result: true. In un sistema distribuito, partial availability è meglio di total failure

D. Overhead HTTP
Stai usando Flask (HTTP/1.1) per trasferire Chunk binari. Per file piccoli (1MB) va bene, ma l'overhead degli header HTTP e la codifica base64 (se JSON) o multipart è alto.

Valutazione: Per un progetto universitario va benissimo HTTP. Non cambiarlo. Ma nel report, nella sezione "Performance Analysis", scrivi che il collo di bottiglia è il protocollo HTTP e che un'implementazione industriale userebbe gRPC o TCP raw. Dimostra consapevolezza.

E. GUI con funzionalità tipo ricerca da mostrare nella demo

F. Capire cosa poter mostrare facilmente della p4p e farci qualche benchmark per confronto